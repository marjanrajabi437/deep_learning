{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6788aef474ca12",
   "metadata": {
    "collapsed": false,
    "id": "7c6788aef474ca12"
   },
   "source": [
    "# Text Generation with Recurrent Neural Networks (RNNs)\n",
    "\n",
    "In this assignment, you'll build upon your understanding of RNNs and Keras to develop a word-level text generation model.  Your goal is to train a model that learns the stylistic nuances of a chosen corpus and generates new, original text segments that echo the source material's essence.\n",
    "\n",
    "**Datasets**\n",
    "\n",
    "We've provided several intriguing text corpora to get you started:\n",
    "\n",
    "*   Mark Twain\n",
    "*   Charles Dickens\n",
    "*   William Shakespeare\n",
    "\n",
    "**Feel free to explore!**  If you have a particular passion for another author, genre, or a specific text, you're encouraged to use your own dataset of raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0bfedcfe52aedc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d0bfedcfe52aedc",
    "outputId": "ced2af65-e9db-43d4-b3b6-1780f64ce0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. If you're on Colab, go to Runtime > Change runtime and select a GPU hardware accelerator.\n"
     ]
    }
   ],
   "source": [
    "# Check if we have a GPU available\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"No GPU available. If you're on Colab, go to Runtime > Change runtime and select a GPU hardware accelerator.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c28c497f620b775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:30:44.959803Z",
     "start_time": "2024-02-08T21:30:44.701343Z"
    },
    "id": "9c28c497f620b775"
   },
   "outputs": [],
   "source": [
    "def download_file(url, file_path):\n",
    "    import requests\n",
    "    r = requests.get(url)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "def load_dataset(file_path, fraction=1.0):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "    return raw_text[:int(fraction * len(raw_text))]\n",
    "\n",
    "dataset = 'shakespeare.txt' # Other options are mark_twain.txt, charles_dickens.txt\n",
    "\n",
    "download_file(f'https://github.com/UofT-DSI/deep_learning/raw/main/assignments/downloaded_books/' + dataset, dataset)\n",
    "\n",
    "# Load chosen dataset. NOTE: If Colab is running out of memory, change the `fraction` parameter to a value between 0 and 1 to load less data.\n",
    "text = load_dataset(dataset, fraction=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab51c764031e606",
   "metadata": {
    "collapsed": false,
    "id": "dab51c764031e606"
   },
   "source": [
    "# 1. Data Preparation (Complete or Incomplete)\n",
    "\n",
    "Before we can begin training an RNN model, we need to prepare the dataset. This involves cleaning the text, tokenizing words, and creating sequences the model can be trained on.\n",
    "\n",
    "## 1.1 Data Exploration\n",
    "\n",
    "Print the first 1000 characters of the dataset. Report the dataset's size and the number of unique characters it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "BunkZmdkl0Wn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BunkZmdkl0Wn",
    "outputId": "00482906-3e5f-474a-eb15-ecdbbdd0effd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 1000 characters of the dataset:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html\n",
      "  lang=\"en\"\n",
      "  \n",
      "  data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-theme=\"dark\"\n",
      "  data-a11y-animated-images=\"system\" data-a11y-link-underlines=\"true\"\n",
      "  \n",
      "  >\n",
      "\n",
      "\n",
      "\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">\n",
      "  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">\n",
      "  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">\n",
      "  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">\n",
      "  <link rel=\"preconnect\" href=\"https://github.githubassets.com\" crossorigin>\n",
      "  <link rel=\"preconnect\" href=\"https://avatars.githubusercontent.com\">\n",
      "\n",
      "      <link rel=\"preload\" href=\"https://github.githubassets.com/assets/global-banner-disable-f988792be49f.js\" as=\"script\" crossorigin>\n",
      "\n",
      "  <link rel=\"preload\" href=\"https://github.githubassets.com/assets/mona-sans-d1bf285e9b9b.woff2\" as=\"font\" type=\"font/woff2\" crossorigin>\n",
      "\n",
      "\n",
      "  <link crossorigin=\"anonymous\" media=\"all\" rel=\"st\n",
      "\n",
      "Dataset size (number of characters): 27040\n",
      "Number of unique characters in the dataset: 88\n"
     ]
    }
   ],
   "source": [
    "# Print the first 1000 characters of the dataset\n",
    "print(\"First 1000 characters of the dataset:\\n\")\n",
    "print(text[:1000])\n",
    "# Report the dataset's size (number of characters)\n",
    "dataset_size = len(text)\n",
    "print(\"\\nDataset size (number of characters):\", dataset_size)\n",
    "\n",
    "# Report the number of unique characters\n",
    "unique_characters = set(text)\n",
    "print(\"Number of unique characters in the dataset:\", len(unique_characters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1639f5ecfe587",
   "metadata": {
    "collapsed": false,
    "id": "3ae1639f5ecfe587"
   },
   "source": [
    "## 1.2 Text Pre-Processing\n",
    "\n",
    "To prepare the dataset for training, we need to clean the text and create a numerical representation the model can interpret. Perform the following pre-processing steps:\n",
    "\n",
    "*   Convert the entire text to lowercase.\n",
    "*   Use the `Tokenizer` class from the `keras.preprocessing.text` module to tokenize the text. You should fit the tokenizer on the text and then convert the text to a sequence of numbers. You can use the `texts_to_sequences` method to do this.\n",
    "\n",
    "**Note**:\n",
    "* You'll need to specify an appropriate size for the vocabulary. The number of words in the list of most common words can serve as a guide - does it seem like a reasonable vocabulary size?\n",
    "* Some of the words will be excluded from the vocabulary, as they don't appear often enough. It's important to provide a value for `oov_token` when creating the Tokenizer instance, so that these words can be represented as \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0d30cd98ea453c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d0d30cd98ea453c",
    "outputId": "4abce580-ed2e-4e09-b7a6-2023bcbd57ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atcVy0Ri0t_A",
   "metadata": {
    "id": "atcVy0Ri0t_A"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dV5NkVX1Mks",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dV5NkVX1Mks",
    "outputId": "eea8f7ca-920b-4538-9f87-14b32cf20d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # Should print the TensorFlow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eOb6_j80YAO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eOb6_j80YAO",
    "outputId": "093a68d3-13b9-429d-dec6-6a706d80c09e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 821 (including OOV token)\n",
      "Index of OOV token: 1\n",
      "Sample sequences (first 20 tokens): [371, 114, 114, 372, 235, 16, 38, 236, 93, 16, 54, 56, 54, 16, 51, 56, 51, 16, 237, 373]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Convert the text to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Define the vocabulary size\n",
    "VOCAB_SIZE = 5000  # Adjust this value as needed\n",
    "OOV_TOKEN = \"<OOV>\"  # Token for out-of-vocabulary words\n",
    "\n",
    "# Create a Tokenizer instance with an OOV token\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOKEN)\n",
    "\n",
    "# Fit the tokenizer on the text\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "# Convert the text to sequences of numbers\n",
    "sequences = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "# Check tokenizer outputs\n",
    "word_index = tokenizer.word_index  # Get the mapping of words to their indices\n",
    "\n",
    "print(f\"Vocabulary size: {len(word_index)} (including OOV token)\")\n",
    "print(f\"Index of OOV token: {word_index[OOV_TOKEN]}\")\n",
    "print(f\"Sample sequences (first 20 tokens): {sequences[:20]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d32bb9356f711",
   "metadata": {
    "collapsed": false,
    "id": "89d32bb9356f711"
   },
   "source": [
    "If everything worked, the following line should show you the first 10 words in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7cd547a19feece",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a7cd547a19feece",
    "outputId": "e6420549-7925-453b-e01b-f7c5f5a0724c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<OOV>', 1), ('github', 2), ('com', 3), ('script', 4), ('https', 5), ('defer', 6), ('1', 7), ('js', 8), ('assets', 9), ('githubassets', 10)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(list(tokenizer.word_index.items())[:10])\n",
    "except AttributeError:\n",
    "    print(\"Tokenizer has not been initialized. Possible issue: Complete the relevant section of the assignment to initialize it.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da504e4bc6617613",
   "metadata": {
    "collapsed": false,
    "id": "da504e4bc6617613"
   },
   "source": [
    "## 1.3 Sequence Generation\n",
    "\n",
    "Now that the text has been tokenized, we need to create sequences the model can be trained on. There are two parts to this:\n",
    "\n",
    "*   Use the `texts_to_sequences` method from the tokenizer to convert the text to a list of sequences of numbers.\n",
    "*   Generate the training sequences. Each training sequence should contain `SEQ_LENGTH` token IDs from the text. The target token for each sequence should be the word that follows the sequence in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff5fc8d0273709c",
   "metadata": {
    "id": "4ff5fc8d0273709c"
   },
   "outputs": [],
   "source": [
    "# Define the sequence length\n",
    "SEQ_LENGTH = 50  # Choose an appropriate sequence length\n",
    "\n",
    "# Convert the text to a list of sequences of numbers\n",
    "sequences = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "# Generate the training sequences\n",
    "X = []  # Input sequences\n",
    "y = []  # Targets\n",
    "\n",
    "# Loop through the tokenized text to create sequences and targets\n",
    "for i in range(len(sequences) - SEQ_LENGTH):\n",
    "    # Input sequence\n",
    "    seq = sequences[i:i + SEQ_LENGTH]\n",
    "    # Target token (the token following the sequence)\n",
    "    target = sequences[i + SEQ_LENGTH]\n",
    "\n",
    "    X.append(seq)\n",
    "    y.append(target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6bdc0deb930df1",
   "metadata": {
    "collapsed": false,
    "id": "3b6bdc0deb930df1"
   },
   "source": [
    "Assuming your sequences are stored in `X` and the corresponding targets in `y`, the following line should print the first training sequence and its target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a495cab04001ce92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a495cab04001ce92",
    "outputId": "5fd79f2d-2747-40c1-a3b7-e7e5db0b01da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: [371, 114, 114, 372, 235, 16, 38, 236, 93, 16, 54, 56, 54, 16, 51, 56, 51, 16, 237, 373, 238, 374, 16, 237, 20, 375, 43, 239, 15, 376, 377, 240, 20, 29, 138, 139, 25, 5, 2, 10, 3, 20, 29, 138, 139, 25, 5, 241, 182, 3]\n",
      "Target: 20\n",
      "Translated back to words: ['doctype', 'html', 'html', 'lang', 'en', 'data', 'color', 'mode', 'auto', 'data', 'light', 'theme', 'light', 'data', 'dark', 'theme', 'dark', 'data', 'a11y', 'animated', 'images', 'system', 'data', 'a11y', 'link', 'underlines', 'true', 'head', 'meta', 'charset', 'utf', '8', 'link', 'rel', 'dns', 'prefetch', 'href', 'https', 'github', 'githubassets', 'com', 'link', 'rel', 'dns', 'prefetch', 'href', 'https', 'avatars', 'githubusercontent', 'com'] -> link\n"
     ]
    }
   ],
   "source": [
    "if len(X) > 0 and len(y) > 0:\n",
    "    print(f'Sequence: {X[0]}\\nTarget: {y[0]}')\n",
    "    print(f'Translated back to words: {[tokenizer.index_word[i] for i in X[0]]} -> {tokenizer.index_word[y[0]]}')\n",
    "else:\n",
    "    print(\"Training sequences have not been generated. Possible issue: Complete the relevant section of the assignment to initialize it.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb2c55da17aaa0",
   "metadata": {
    "collapsed": false,
    "id": "d5bb2c55da17aaa0"
   },
   "source": [
    "And the following code will transform y into a one-hot encoded matrix, and split everything into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a929b2e6c2cc921",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a929b2e6c2cc921",
    "outputId": "a666d74e-6958-4a2c-8c49-f30c2271f1f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3027, 50)\n",
      "y_train shape: (3027, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Ensure that tokenizer has been initialized\n",
    "if tokenizer is not None:\n",
    "    # Convert X and y to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # One last thing: let's drop any examples where the target is the OOV token - we don't want our model to predict that (boring!)\n",
    "    if OOV_TOKEN in tokenizer.word_index:\n",
    "        mask = y != tokenizer.word_index[OOV_TOKEN]\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "\n",
    "    # One-hot encode the target token\n",
    "    y = to_categorical(y, num_classes=VOCAB_SIZE)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f'X_train shape: {X_train.shape}')\n",
    "    print(f'y_train shape: {y_train.shape}')\n",
    "else:\n",
    "    print(\"Tokenizer has not been initialized. Please initialize it and load the vocabulary before continuing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e4161897210434",
   "metadata": {
    "collapsed": false,
    "id": "b6e4161897210434"
   },
   "source": [
    "# 2. Model Development (Complete or Incomplete)\n",
    "\n",
    "With the dataset prepared, it's time to develop the RNN model. You'll need to define the architecture of the model, compile it, and prepare it for training.\n",
    "\n",
    "## 2.1 Model Architecture\n",
    "\n",
    "Define the architecture of your RNN model. You can design it however you like, but there are a few features that it's important to include:\n",
    "\n",
    "*   An embedding layer that learns a dense representation of the input tokens. You'll need to specify the input dimension (the size of the vocabulary) and the output dimension (the size of the dense representation). Remember, you can look at the documentation [here](https://keras.io/api/layers/core_layers/embedding/).\n",
    "*   At least one recurrent layer. We have learned how to use LSTM layers in class, but you can use other types of recurrent layers if you prefer. You can find the documentation [here](https://keras.io/api/layers/recurrent_layers/lstm/).\n",
    "*   A dense layer with a softmax activation function. This layer will output a probability distribution over the vocabulary, so that the model can make predictions about the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33hg5MubOJmn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33hg5MubOJmn",
    "outputId": "cd533c52-bad1-469a-ec41-5a0d6abcfb31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 (3027, 5000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(VOCAB_SIZE , y_train.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fdfaad93818fc8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fdfaad93818fc8d",
    "outputId": "75660fc3-864c-4bf8-8d8b-9277dd75ec35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.conda\\envs\\dsi_participant3\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Embedding name=embedding, built=False>,\n",
       " <LSTM name=lstm, built=False>,\n",
       " <Dense name=dense, built=False>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    # Embedding layer: Convert input tokens to dense representations\n",
    "    Embedding(input_dim=VOCAB_SIZE, output_dim=128, input_length=SEQ_LENGTH),\n",
    "\n",
    "    # Recurrent layer (LSTM)\n",
    "    LSTM(128, return_sequences=False),  # You can change the number of units (128) if needed\n",
    "\n",
    "    # Dense layer with softmax activation\n",
    "    Dense(VOCAB_SIZE, activation='softmax')  # Output layer to predict next token\n",
    "])\n",
    "model.layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "iY6cLB6gTa-D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "iY6cLB6gTa-D",
    "outputId": "b6ecd78a-772d-4fff-886a-c992689e9da2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if the model has layers before trying to print the summary\n",
    "\n",
    "if len(model.layers) > 0:\n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"No layers have been added to the model. Please complete the assignment by adding the required layers.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fafd2dbb0d589fc",
   "metadata": {
    "collapsed": false,
    "id": "2fafd2dbb0d589fc"
   },
   "source": [
    "## 2.2 Model Compilation\n",
    "\n",
    "Compile the model with an appropriate loss function and optimizer. You might also want to track additional metrics, such as accuracy.\n",
    "\n",
    "Give a short explanation of your choice of loss function and optimizer:\n",
    "\n",
    "_your explanation here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4ca7a12051b1fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "ae4ca7a12051b1fd",
    "outputId": "3b9cd5f4-c008-4e94-f9a7-8624995ca31a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model with an appropriate loss function and optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0b90a448c4f4b",
   "metadata": {
    "collapsed": false,
    "id": "c2f0b90a448c4f4b"
   },
   "source": [
    "## 2.3 Model Training\n",
    "\n",
    "Train the model on the training data you've prepared.\n",
    "\n",
    "* Train your model for 5 epochs with a batch size of 128. Use the validation data for validation.\n",
    "* Store the training history in a variable called `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "w3950SR4cod9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3950SR4cod9",
    "outputId": "bb1c28f2-269b-4303-f8c8-92d06d177291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f3EI5c-gR",
   "metadata": {
    "id": "d59f3EI5c-gR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "256b1ea138c67ef7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "256b1ea138c67ef7",
    "outputId": "d2a2c1c1-2cc1-4db2-d1c4-159274d90da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.0573 - loss: 8.4185 - val_accuracy: 0.0264 - val_loss: 7.0360\n",
      "Epoch 2/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.0372 - loss: 6.2570 - val_accuracy: 0.0264 - val_loss: 6.4067\n",
      "Epoch 3/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.0321 - loss: 5.6415 - val_accuracy: 0.0264 - val_loss: 6.4891\n",
      "Epoch 4/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.0309 - loss: 5.5953 - val_accuracy: 0.0264 - val_loss: 6.5103\n",
      "Epoch 5/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.0343 - loss: 5.5148 - val_accuracy: 0.0264 - val_loss: 6.5281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c59bf80d2a2c4",
   "metadata": {
    "collapsed": false,
    "id": "195c59bf80d2a2c4"
   },
   "source": [
    "Plot the training history to visualize the model's learning progress. Your plot should include the training and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8cacec70d8f313",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "9e8cacec70d8f313",
    "outputId": "3697ce70-4700-416c-964b-c34958bb31c2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "\n",
    "# Plot validation loss\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ed71305787aed",
   "metadata": {
    "collapsed": false,
    "id": "3d9ed71305787aed"
   },
   "source": [
    "# 3. Text Generation (Complete or Incomplete)\n",
    "\n",
    "Write a method called `generate_text` that uses the trained model to generate new text. The method should take the following parameters:\n",
    "\n",
    "*   `model`: The trained RNN model.\n",
    "*   `tokenizer`: The tokenizer used to pre-process the text data.\n",
    "*   `seed_text`: The seed text the model will use to generate new text.\n",
    "*   `max_sequence_len`: The maximum length of the sequence used to generate new text.\n",
    "\n",
    "The method should return the generated text.\n",
    "\n",
    "An overview of the text generation process you should follow:\n",
    "\n",
    "1. Tokenize the seed text using the tokenizer we built before.\n",
    "2. Pad the sequences to the same length as the training sequences - you can use the `pad_sequences` method from the `keras.preprocessing.sequence` module, which is documented [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences).\n",
    "3. Use the model to predict the next token in the sequence. Remember that the model will output a probability distribution over the vocabulary, so you'll need to use `np.argmax` to find the token with the highest probability.\n",
    "4. Add the predicted token to the sequence and remove the first token.\n",
    "5. Repeat steps 3-4 until you have generated the desired number of tokens.\n",
    "6. Convert the generated token IDs back to words and return the combined result as a single string.\n",
    "\n",
    "This is a challenging task, so don't hesitate to ask for help if you need it. It's okay if the generated text doesn't make much sense yet - we'll work on improving the model next.\n",
    "As a bonus, you can make your method generate \"gpt-style\" by having it print out each word as it's generated, so you can see the text being generated in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "MUzVyk1_malL",
   "metadata": {
    "id": "MUzVyk1_malL"
   },
   "outputs": [],
   "source": [
    "texts = [\"hamlet\", \"to be or not to be\", \"that is the question\"]\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "QpmZdvnRmtzj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpmZdvnRmtzj",
    "outputId": "406a7c95-0270-4a41-db86-4b312c4ac22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "texts = [\"to be or not to be\", \"that is the question\"]\n",
    "tokenizer.fit_on_texts(texts)  # Train tokenizer on sample text\n",
    "\n",
    "text = \"hamlet\"\n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "print(sequence)  # Will return [[1]] because \"hamlet\" is treated as OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "IXyDTHjJmmG1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXyDTHjJmmG1",
    "outputId": "2ce7c671-c42e-4879-9550-dce27e6836d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Sequence: [[0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Tokenizer setup and model definition\n",
    "SEQ_LENGTH = 10\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "texts = [\"to be or not to be\", \"that is the question\"]  # Training data for the tokenizer\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=256, input_length=SEQ_LENGTH),\n",
    "    LSTM(128),\n",
    "    Dense(5000, activation='softmax')\n",
    "])\n",
    "\n",
    "# Preprocess text and pad sequences\n",
    "text = \"hamlet\"\n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "if sequence and sequence[0]:  # Ensure sequence is not empty\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=SEQ_LENGTH)\n",
    "    print(\"Padded Sequence:\", padded_sequence)\n",
    "else:\n",
    "    print(\"No valid sequence generated. Check the vocabulary or text input.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tWRxtBtKrLiz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWRxtBtKrLiz",
    "outputId": "bc249e8a-e0af-4a6f-df1f-918255d11801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token ID in vocabulary: 9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum token ID in vocabulary: {max(tokenizer.word_index.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "m4wQxM9hm_CE",
   "metadata": {
    "id": "m4wQxM9hm_CE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def get_predicted_word(model, sequence):\n",
    "    \"\"\"\n",
    "    Get the predicted word from the model.\n",
    "    This helper function adds randomness by sampling based on probabilities (temperature).\n",
    "    \"\"\"\n",
    "    # Use the model to predict the next token in the sequence\n",
    "    yhat = model.predict(sequence, verbose=0)\n",
    "\n",
    "    # Get the index of the predicted word, according to the probabilities\n",
    "    yhat = np.random.choice(range(VOCAB_SIZE), p=yhat.ravel())\n",
    "\n",
    "    return yhat\n",
    "\n",
    "def generate_text(model, tokenizer, seed_text, max_sequence_len, num_tokens_to_generate=50):\n",
    "    \"\"\"\n",
    "    Generate new text using the trained model.\n",
    "\n",
    "    Args:\n",
    "    model: The trained RNN model.\n",
    "    tokenizer: The tokenizer used to pre-process the text data.\n",
    "    seed_text: The initial seed text the model will use to generate new text.\n",
    "    max_sequence_len: The maximum length of the sequence used to generate new text.\n",
    "    num_tokens_to_generate: The number of tokens (words) to generate.\n",
    "\n",
    "    Returns:\n",
    "    The generated text as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Tokenize the seed text\n",
    "    encoded_seed = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\n",
    "    # Step 2: Pad the sequence to match the max sequence length\n",
    "    encoded_seed = pad_sequences([encoded_seed], maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "    # Generate new tokens\n",
    "    generated_text = seed_text\n",
    "\n",
    "    for _ in range(num_tokens_to_generate):\n",
    "        # Step 3: Predict the next word\n",
    "        predicted_token = get_predicted_word(model, encoded_seed)\n",
    "\n",
    "        # Step 4: Add the predicted token to the sequence\n",
    "        generated_word = tokenizer.index_word[predicted_token]\n",
    "        generated_text += ' ' + generated_word\n",
    "\n",
    "        # Update the sequence with the new word\n",
    "        encoded_seed = pad_sequences([encoded_seed[0][1:] + [predicted_token]], maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "qf8kIItZrTQV",
   "metadata": {
    "id": "qf8kIItZrTQV"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seed_text, max_sequence_len, num_tokens_to_generate=50):\n",
    "    generated_text = seed_text\n",
    "\n",
    "    for _ in range(num_tokens_to_generate):\n",
    "        # Step 1: Convert text to sequence\n",
    "        sequence = tokenizer.texts_to_sequences([generated_text])\n",
    "        padded_sequence = pad_sequences(sequence, maxlen=max_sequence_len, truncating='pre')\n",
    "\n",
    "        # Step 2: Predict next word\n",
    "        predicted_probabilities = model.predict(padded_sequence, verbose=0)\n",
    "        predicted_token = predicted_probabilities.argmax()\n",
    "\n",
    "        # Step 3: Handle missing tokens\n",
    "        if predicted_token in tokenizer.index_word:\n",
    "            generated_word = tokenizer.index_word[predicted_token]\n",
    "        else:\n",
    "            generated_word = \"<UNK>\"  # Use a placeholder for unknown tokens\n",
    "\n",
    "        # Step 4: Add the predicted token to the sequence\n",
    "        generated_text += ' ' + generated_word\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f463b0c3df49e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "f463b0c3df49e2c",
    "outputId": "d6bd7ba7-6505-4246-8b1a-d0b8b756ac83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hamlet <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the text generation function\n",
    "generate_text(model, tokenizer, 'hamlet', SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871d836a0135c41",
   "metadata": {
    "collapsed": false,
    "id": "5871d836a0135c41"
   },
   "source": [
    "It's likely that the text generated by your model doesn't make much sense yet. This is because the model hasn't been trained for very long, and the training dataset is relatively small.\n",
    "\n",
    "# 4. Model Refinement (Complete or Incomplete)\n",
    "\n",
    "In this last section, you'll work on improving your model. There are many ways to do this, but here are a few ideas to get you started:\n",
    "\n",
    "* Use pre-trained embeddings: the code below will help you to load pre-trained embeddings through Keras.\n",
    "* Experiment with different model architectures, including the number of layers, the number of units in each layer, and the use of dropout layers.\n",
    "* Train your model for longer. You can also experiment with different batch sizes.\n",
    "\n",
    "Implement and test out at least one of these ideas. If you have other ideas for improving the model, feel free to try them out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dda8b0f845c20862",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dda8b0f845c20862",
    "outputId": "f2c21472-3500-4ada-ee8d-4db1e0614cd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b777220505635",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8b777220505635",
    "outputId": "aad247f1-1640-46cd-eb9b-83f4bec05345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'glove.6B.100d.txt' File not found. Please make sure you have ran the previous cell.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained embeddings\n",
    "embeddings_index = {}\n",
    "try:\n",
    "    with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f'Found {len(embeddings_index)} word vectors.')\n",
    "except FileNotFoundError:\n",
    "    print(\"'glove.6B.100d.txt' File not found. Please make sure you have ran the previous cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3e48ff004757cf2",
   "metadata": {
    "id": "d3e48ff004757cf2"
   },
   "outputs": [],
   "source": [
    "# Check if VOCAB_SIZE is set\n",
    "if VOCAB_SIZE is None:\n",
    "    print(\"You need to complete the previous parts of your assignment in order for this to work.\")\n",
    "else:\n",
    "    # Create an embedding matrix\n",
    "    embedding_matrix = np.zeros((VOCAB_SIZE, 100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i < VOCAB_SIZE:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3d21d5dbbbcf9f9",
   "metadata": {
    "id": "e3d21d5dbbbcf9f9"
   },
   "outputs": [],
   "source": [
    "# Check if VOCAB_SIZE is set\n",
    "if VOCAB_SIZE is None:\n",
    "    print(\"You need to complete the previous parts of your assignment in order for this to work.\")\n",
    "else:\n",
    "    embedding_layer = Embedding(\n",
    "        VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=SEQ_LENGTH, trainable=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236cb723e4e5b3fc",
   "metadata": {
    "id": "236cb723e4e5b3fc"
   },
   "outputs": [],
   "source": [
    "# Define a new model and train it\n",
    "\n",
    "# Initialize the embedding matrix\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, 100))\n",
    "\n",
    "# Fill the embedding matrix with GloVe vectors\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < VOCAB_SIZE:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7KUuIwo0Gvg",
   "metadata": {
    "id": "f7KUuIwo0Gvg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "if 'SEQ_LENGTH' not in globals():\n",
    "    print(\"SEQ_LENGTH is not defined. Please define it first.\")\n",
    "else:\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=VOCAB_SIZE,\n",
    "        output_dim=100,  # GloVe's dimensionality\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=SEQ_LENGTH,\n",
    "        trainable=False  # Freeze pre-trained embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "pROWxVtV0MjL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "pROWxVtV0MjL",
    "outputId": "4b28251c-76fa-401d-c8f5-34ad3fc1257b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │       \u001b[38;5;34m500,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m500,000\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m500,000\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(VOCAB_SIZE, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2hZVTa00RWN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2hZVTa00RWN",
    "outputId": "5b5eedf3-3914-4929-c2b2-a71a8f82904f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.0226 - loss: 7.8347 - val_accuracy: 0.0248 - val_loss: 6.3087\n",
      "Epoch 2/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0459 - loss: 5.8998 - val_accuracy: 0.0248 - val_loss: 6.2123\n",
      "Epoch 3/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0422 - loss: 5.6938 - val_accuracy: 0.0248 - val_loss: 6.2436\n",
      "Epoch 4/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0372 - loss: 5.7576 - val_accuracy: 0.0248 - val_loss: 6.2916\n",
      "Epoch 5/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0321 - loss: 5.6163 - val_accuracy: 0.0248 - val_loss: 6.3403\n",
      "Epoch 6/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0379 - loss: 5.6296 - val_accuracy: 0.0248 - val_loss: 6.3684\n",
      "Epoch 7/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0359 - loss: 5.5493 - val_accuracy: 0.0248 - val_loss: 6.3913\n",
      "Epoch 8/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0365 - loss: 5.5567 - val_accuracy: 0.0248 - val_loss: 6.4140\n",
      "Epoch 9/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0400 - loss: 5.5383 - val_accuracy: 0.0248 - val_loss: 6.4508\n",
      "Epoch 10/10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0379 - loss: 5.5407 - val_accuracy: 0.0248 - val_loss: 6.4795\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742095fb",
   "metadata": {
    "id": "742095fb"
   },
   "source": [
    "## Criteria\n",
    "\n",
    "|Criteria|Complete|Incomplete|\n",
    "|----|----|----|\n",
    "|Task 1|The task has been completed successfully and there are no errors.|The task is still incomplete and there is at least one error.|\n",
    "|Task 2|The task has been completed successfully and there are no errors.|The task is still incomplete and there is at least one error.|\n",
    "|Task 3|The task has been completed successfully and there are no errors.|The task is still incomplete and there is at least one error.|\n",
    "|Task 4|The task has been completed successfully and there are no errors.|The task is still incomplete and there is at least one error.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1990e2d2",
   "metadata": {
    "id": "1990e2d2"
   },
   "source": [
    "## Submission Information\n",
    "\n",
    "🚨**Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)**🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/deep_learning/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dsi_participant3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
